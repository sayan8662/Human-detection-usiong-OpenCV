{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1868f5b",
   "metadata": {},
   "source": [
    "# Human Detection with Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ef3502",
   "metadata": {},
   "source": [
    "Importing the library (cv2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04343cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ffb310",
   "metadata": {},
   "source": [
    "Here we'll be using the \"VideoCapture\" function from the cv2 libraryto access the video file from our system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06e65f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture('in.avi') # we are storing the file to the capture variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1c95f9",
   "metadata": {},
   "source": [
    "Here we are going to use the \"CascadeClassifier\" function from the cv2 library and going to use the 'haarcascade_fullbody.xml', a pre-trained model  file for HUMAN DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daa0182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanCascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ecd09",
   "metadata": {},
   "source": [
    "WE ARE GOING TO USE AN INFINE LOOP TO EMPLEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e621013",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    # Logic for capturing the video frame wise.\n",
    "    rate, frame = capture.read()\n",
    "    \n",
    "    # The operations on a perticular frame done here.\n",
    "    ## for any detection process we need to convert the COLOR image to GRAY scale image\n",
    "    grayscale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #converting each frame color to gray scale\n",
    "    humans = humanCascade.detectMultiScale(grayscale, 1.9,1)\n",
    "    \n",
    "    # This is to display the resulting frame \n",
    "    # the reason for this loop is to identify humans in the video with a rectangular shape\n",
    "    for (x,y,w,h) in humans:\n",
    "        cv2.rectangle(frame,(x,y),(x+w, y+h),(255,0,0),2)\n",
    "        \n",
    "    # Here We are creating a condition for the program to end.\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): # pressing \"q\" vutton on the keyboard is the timeout contition \n",
    "        break\n",
    "        \n",
    "# After completeing, Its time to release the capture\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845ff125",
   "metadata": {},
   "source": [
    "## Striving towards more accuracy..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf62fc",
   "metadata": {},
   "source": [
    "Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18410ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b07d48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionDetection():\n",
    "    capture1 = cv2.VideoCapture('in.avi')\n",
    "    ret, frame1 = capture1.read()\n",
    "    ret, frame2 = capture1.read()\n",
    "    \n",
    "    while capture1.isOpened():\n",
    "        difference = cv2.absdiff(frame1, frame2)  # getting absolute difference of the two frames\n",
    "        differenceGrayScale = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.GaussianBlur(differenceGrayScale,(5,5),0)\n",
    "        _, threshold = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)\n",
    "        dilated = cv2.dilate(threshold, None, iterations = 3)\n",
    "        contours, _ = cv2.findContours(dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        for contour in contours:\n",
    "            (x,y,w,h) = cv2.boundingRect(contour)\n",
    "            if cv2.contourArea(contour) < 900:\n",
    "                continue\n",
    "            cv2.rectangle(frame1, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "            cv2.putText(frame1, \"Pedestrian()\".format('Movement'), (10,20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "            \n",
    "        cv2.imshow('Video',frame1)\n",
    "        frame1 = frame2\n",
    "        ret, frame2 = capture1.read()\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # pressing \"q\" vutton on the keyboard is the timeout contition \n",
    "            break\n",
    "    \n",
    "    # After completeing, Its time to release the capture\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "   motionDetection() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1f345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
